{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788a9b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Getting Data---\n",
      "Loaded: Streaming_History_Audio_2021_8.json\n",
      "Loaded: Streaming_History_Audio_2022_12.json\n",
      "Loaded: Streaming_History_Audio_2021-2022_10.json\n",
      "Loaded: Streaming_History_Audio_2023-2024_17.json\n",
      "Loaded: Streaming_History_Audio_2019_1.json\n",
      "Loaded: Streaming_History_Audio_2020_4.json\n",
      "Loaded: Streaming_History_Audio_2020_3.json\n",
      "Loaded: Streaming_History_Audio_2021_9.json\n",
      "Loaded: Streaming_History_Audio_2021_6.json\n",
      "Loaded: Streaming_History_Audio_2025_22.json\n",
      "Loaded: Streaming_History_Audio_2024_18.json\n",
      "Loaded: Streaming_History_Audio_2021_7.json\n",
      "Loaded: Streaming_History_Audio_2020-2021_5.json\n",
      "Loaded: Streaming_History_Audio_2024-2025_20.json\n",
      "Loaded: Streaming_History_Audio_2024_19.json\n",
      "Loaded: Streaming_History_Audio_2022_11.json\n",
      "Loaded: Streaming_History_Audio_2023_14.json\n",
      "Loaded: Streaming_History_Audio_2023_16.json\n",
      "Loaded: Streaming_History_Audio_2019-2020_2.json\n",
      "Loaded: Streaming_History_Audio_2023_15.json\n",
      "Loaded: Streaming_History_Audio_2015-2019_0.json\n",
      "Loaded: Streaming_History_Audio_2025_21.json\n",
      "Loaded: Streaming_History_Audio_2022-2023_13.json\n",
      "\n",
      "Total raw streams loaded: 359043\n",
      "âœ… Sensitive columns scrubbed from data in memory.\n",
      "Total streams after removing skips (<30s): 124280\n",
      "saved clean history!\n",
      "Saved 8520 unique tracks\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "project_path = '/home/me/dev/spotanalysis'\n",
    "\n",
    "\n",
    "raw_data = os.path.join(project_path, 'data', 'raw')\n",
    "processed_data = os.path.join(project_path,'data', 'processed')\n",
    "all_streams = []\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "print(\"---Getting Data---\")\n",
    "for filename in os.listdir(raw_data):\n",
    "    if filename.startswith('Streaming_History_Audio') and filename.endswith('.json'):\n",
    "        file_path = os.path.join(raw_data, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                all_streams.extend(data)\n",
    "                print(f\"Loaded: {filename}\")\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error reading JSON from {filename}. Skipping.\")\n",
    "\n",
    "# Convert dictionaries to pandas Data Frame\n",
    "df_history = pd.DataFrame(all_streams)\n",
    "print(f\"\\nTotal raw streams loaded: {len(df_history)}\")\n",
    "\n",
    "drop_columns = ['ip_addr', 'conn_country', 'platform', 'incognito_mode', 'offline_timestamp']\n",
    "df_history.drop(columns=drop_columns, inplace=True, errors='ignore')\n",
    "print(\"Sensitive columns scrubbed from data in memory.\")\n",
    "\n",
    "#convert endtime column to datetime endtime\n",
    "df_history['ts'] = pd.to_datetime(df_history['ts'])\n",
    "\n",
    "#Songs under 30s don't count as a stream. \n",
    "df_history_clean = df_history[df_history['ms_played'] >= 30000].copy()\n",
    "print(f\"Total streams after removing skips (<30s): {len(df_history_clean)}\")\n",
    "\n",
    "#cleaning \n",
    "df_history_clean['HourOfDay'] = df_history_clean['ts'].dt.hour\n",
    "df_history_clean['DayOfWeek'] = df_history_clean['ts'].dt.day_name()\n",
    "df_history_clean['Date'] = df_history_clean['ts'].dt.date\n",
    "\n",
    "#Removing repeat songs\n",
    "unique_tracks = df_history_clean[['master_metadata_album_artist_name', 'master_metadata_track_name']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "df_history_clean.to_csv(os.path.join(processed_data,'clean_history.csv'), index=False)\n",
    "unique_tracks.to_csv(os.path.join(processed_data, 'unique_tracks.csv'), index=False)\n",
    "\n",
    "print(\"saved clean history!\")\n",
    "print(f\"Saved {len(unique_tracks)} unique tracks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55a68f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spotanalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
